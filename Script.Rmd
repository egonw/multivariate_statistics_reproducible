# Systems Biology Scientific Programming

---
title: "Assignment 2: Multivariate statistics reproducible"
author: "Stijn Hanssen"
date: "Oktober 2018"
output: html_document
---

### Clear working space
First step is to make sure that the working space is empty.
```{r}
# clear all variables
rm(list=ls()) 
```

### Set path working directory
The directory path is set to the stored datasets.
```{r}
# set working directory
setwd("C:/Users/stijn/Desktop/Master systems biology/Systems biology year 2/scientific computing/statistic") 
```

### Load libraries
Loading the required packages for specific functions. 
```{r}
# pls: used for the multivariate regression methods partial least squares regression
library(pls) 
# caTools: the package inclused basic static functions. for random sampeling
library(caTools)
```

### Import assay data
The first dataset that is imported is the assay data from PubMech (AID_624202). The first 6 lines will be skipped for the reason that they don't contain relevant information. Only the SID and Score collumns will be selected from this dataset.
```{r}
# Read CSV file, skip first 6 lines
assayData = read.csv(
  file='AID_624202_datatable.csv',
  header=FALSE, skip=6
) 
# check the rows and collumns
dim(assayData) 
# inspect the first 5 lines
head(assayData,n=5) 
# keep the SID and Score column
assayData = assayData[,c("V2","V5")] 
# change the column names
colnames(assayData) = c("SID","Score") 
dim(assayData)
head(assayData,n=5)
```

### Import descriptors file
In this section will the descriptors file be loaded.
For the development of the discriptor file go to: [descriptors.Rmd](https://github.com/egonw/scientificProgramming/blob/master/assignment%202/descriptors.Rmd).
The `descriptors.Rmd` uses the downloaded assay data from PubMech (AID_624202).
```{r}
discriptorData = read.csv(
  file='descriptors.csv',
  header=TRUE,row.names = 2
)
dim(discriptorData)
head(discriptorData,n=5)
# Delete "X" column, which only contains numbers
discriptorData = discriptorData[,-1] 
dim(discriptorData)
head(discriptorData,n=5)
```

### Match SID
The SID column from both data sets will be match, in order to add the score column to the discriptorData. In the variable data is the complete dataset stored
```{r}
# Match by SID
data = assayData[match(rownames(discriptorData),assayData$SID),] 
# add the score column to the discriptordata
data = cbind(discriptorData,data$Score) 
dim(data)
head(data,n=5)
```
### Data cleaning (remove NA and 0 collumns)
During data inspection, it came to the attation that there are columns with only NA values and columns with no variance. These column wont have any added value to the prediction model and thus will be removed.
```{r}
# check for columns with NA and remove them
data = data[, colSums(is.na(data)) != nrow(data)]
dim(data)
head(data,n=5)
# filter out the columns with no variance
data = Filter(var,data) 
dim(data)
head(data,n=5)
```

### Split into train and test data
The `caTools` library is used to randomly generate train and test data. 80 percent of the data will be used as training data while the other 20 precent will be used as test data.
```{r}
# set the seed for the reason that always the same sequence will be generated
set.seed(101) 
# random sample of 80 percent
sample = sample.split(data, SplitRatio = .80) 
# subset the 80 percent data
train = subset(data, sample == TRUE) 
# store the score in a variable
train_y = train$`data$Score` 
# subset the 20 percent data
test  = subset(data, sample == FALSE) 
test_y = test$`data$Score`
```

### Partial Least Squares (pls) model 
The `pls` library is used for the development of the prediction model. pls is being used for the reason that there are relativily many predictor variables and relativly a few samples.
```{r}
# fitting the PLS model. score agianst all other variables. the model is fit with 10 components
pls_model <- plsr(`data$Score` ~ .,ncomp = 10, data = train) 
# overview of the fit and validation results
summary(pls_model) 
# cross validation divided into segments of 10
pls_model_CV <- plsr(`data$Score` ~ .,ncomp = 10, data = train,validation = "CV") 
summary(pls_model_CV)
```

### plot Root Mean Squared Error of Prediction (RMSEP)
RMSE measures how spread out the residuals are. The summary above showed two cross validation estimates, the ordinary CV and the adjCV which is a bias-correctd CV estimate. three components seem to be enough 

```{r}
# plots the estimated RMSEP as a function of the number of components. legendpos indicated the legend position
plot(RMSEP(pls_model_CV), legendpos="topright") 
```

### plot the third component prediction on the training set
The plot shows the cross validated prediction by use of the third components.  
```{r}
# use the plot function for prediction, number of component was selected from the above figure, aspect ratio on 1 to produce a plot where distance between oints are accurate, line arguement for regression line
plot(pls_model_CV, ncomp = 3, asp = 1, line = TRUE)
```

### Pairwise plot
The score values of the first three components are shown. These plots are used to see patterns, groups and/or outleirs in the data. Behind each component are relative amount of variance explained by each components, these are explict extracted by `explvar` function. explained variance: proportion mathemaical model acount for variation of the  dataset.
```{r}
plot(pls_model_CV, plottype = "scores", comps = 1:3)
# extract amount of variance explianed for each component in the model
explvar(pls_model_CV)
```

### Predict on test set
The pls fitted model is being used to predict the values of the test data.
```{r}
# store the prediction  as a data frame
prediction = as.data.frame(predict(pls_model_CV, ncomp = 3, newdata = test))
# combine the predicted values with the true values
prediction_and_true_values = cbind(prediction,test_y)
# show the first 20 rows
head(prediction_and_true_values,n=20)
```

### RMSEP test set
The component score seems to be quite close to the cross-validated estimate of the train RMSEP
```{r}
RMSEP(pls_model_CV, newdata = test)
```

### plot test set
The plot shows the measured value's versus the predicted values. 
```{r}
# predplot is used because it plots the prior predictive distribution of the number of successes in the trail
predplot(pls_model_CV, ncomp = 3, newdata = test, asp = 1, line = TRUE)
```

